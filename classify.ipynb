{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb5116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wzhzhang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[WARNING] From c:\\Users\\wzhzhang\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "[INFO] PyTorch version 2.5.1+cu121 available.\n",
      "[INFO] TensorFlow version 2.19.0 available.\n"
     ]
    }
   ],
   "source": [
    "from parser.models.question import (\n",
    "    Question,\n",
    "    SubQuestion,\n",
    "    SubSubQuestion,\n",
    "    MultipleChoiceQuestion,\n",
    ")\n",
    "from parser.models.syllabus import Syllabus\n",
    "from parser.sq_ms_parser import SQMSParser\n",
    "from parser.sq_parser import QuestionPaperParser\n",
    "from parser.syllabus_parser import SyllabusParser\n",
    "import pdfplumber\n",
    "import pprint\n",
    "from typing import List, Optional\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMClassifier:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        syllabuses: List[Syllabus],\n",
    "        batch_size: int = 64,\n",
    "        cache_path: str = \"syllabus_embeddings.pkl\",\n",
    "        model_name: str = \"allenai/scibert_scivocab_uncased\",\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def classify_all(\n",
    "        self, questions: List[Question | MultipleChoiceQuestion]\n",
    "    ) -> List[Question | MultipleChoiceQuestion]:\n",
    "        for question in tqdm.tqdm(questions, desc=\"Classifying questions\"):\n",
    "            self.classify(question)\n",
    "        return questions\n",
    "\n",
    "    def classify(\n",
    "        self, question: MultipleChoiceQuestion | Question | SubQuestion | SubSubQuestion\n",
    "    ) -> None:\n",
    "        if isinstance(question, MultipleChoiceQuestion):\n",
    "            question.syllabus = self.get_best_syllabus(question.text)\n",
    "            return\n",
    "        elif isinstance(question, SubQuestion):\n",
    "            if question.subsubquestions:\n",
    "                for subsubquestion in question.subsubquestions:\n",
    "                    self.classify(subsubquestion)\n",
    "        elif isinstance(question, Question):\n",
    "            if question.subquestions:\n",
    "                for subquestion in question.subquestions:\n",
    "                    self.classify(subquestion)\n",
    "\n",
    "        # Combine question text and answer for better matching\n",
    "        question_text = (\n",
    "            question.text + \" \" + (question.answer if question.answer else \"\")\n",
    "        )\n",
    "        question.syllabus = self.get_best_syllabus(question_text)\n",
    "\n",
    "    def get_best_syllabus(self, question_sentence: str, threshold=0.3) -> Syllabus:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e86c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] \u001b[1;36m[1/4] Opening document...\u001b[0m\n",
      "[INFO] \u001b[1;36m[2/4] Analyzing document...\u001b[0m\n",
      "[WARNING] Ignore Line \"<image>\" due to overlap\n",
      "[INFO] \u001b[1;36m[3/4] Parsing pages...\u001b[0m\n",
      "[INFO] (1/15) Page 1\n",
      "[INFO] (2/15) Page 2\n",
      "[INFO] (3/15) Page 3\n",
      "[INFO] (4/15) Page 4\n",
      "[INFO] (5/15) Page 5\n",
      "[INFO] (6/15) Page 6\n",
      "[INFO] (7/15) Page 7\n",
      "[INFO] (8/15) Page 8\n",
      "[INFO] (9/15) Page 9\n",
      "[INFO] (10/15) Page 10\n",
      "[INFO] (11/15) Page 11\n",
      "[INFO] (12/15) Page 12\n",
      "[INFO] (13/15) Page 13\n",
      "[INFO] (14/15) Page 14\n",
      "[INFO] (15/15) Page 15\n"
     ]
    }
   ],
   "source": [
    "with pdfplumber.open(\"papers/595426-2023-2025-syllabus.pdf\") as syllabus_pdf:\n",
    "        syllabus_parser = SyllabusParser(syllabus_pdf, pages=(12, 46))\n",
    "        syllabuses = syllabus_parser.parse_syllabus()\n",
    "with pdfplumber.open(\"papers/igcse-biology-0610/0610_w22_qp_42.pdf\") as qppdf:\n",
    "    sq_parser = QuestionPaperParser(qppdf, image_prefix=\"0610_w22_qp_42\")\n",
    "    questions = sq_parser.parse_question_paper()\n",
    "sqms_parser = SQMSParser(\"papers/igcse-biology-0610/0610_w22_ms_42.pdf\", questions)\n",
    "questions = sqms_parser.parse_ms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b3444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SentenceTransformer with model: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Use pytorch device_name: cuda:0\n",
      "[INFO] Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings from cache: biology_syllabus.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s]?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.27it/s]05,  1.18s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.00it/s]02,  1.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.96it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.64it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.94it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.48it/s]02,  1.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 25.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 10.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 32.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s]01,  1.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.48it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 28.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.79it/s]00,  1.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.60it/s]\n",
      "Classifying questions: 100%|██████████| 6/6 [00:03<00:00,  1.53it/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = LLMClassifier(syllabuses, cache_path=\"biology_syllabus.pt\")\n",
    "questions = classifier.classify_all(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f223bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question_hierarchy(questions):\n",
    "    output = \"\"\n",
    "    for q in questions:\n",
    "        output += f\"{q.text}\\n{q.syllabus.title if hasattr(q, \"syllabus\") else \"\"}\\n \"\n",
    "        if q.subquestions:\n",
    "            for sub_q in q.subquestions:\n",
    "                text = sub_q.text.strip()\n",
    "                output += f\"\\n    {text}\\n{sub_q.syllabus.title if hasattr(sub_q, \"syllabus\") else \"\"}\"\n",
    "                if sub_q.subsubquestions:\n",
    "                    for subsub_q in sub_q.subsubquestions:\n",
    "                        text = subsub_q.text.strip()\n",
    "                        subsub_q: SubSubQuestion\n",
    "                        output += f\"\\n        {text}\\n{subsub_q.syllabus.title if hasattr(subsub_q, \"syllabus\") else \"\"}\\n\"\n",
    "        output += \"\\n\" + \"-\" * 80 + \"\\n\"\n",
    "    return output.strip()\n",
    "with open(\"output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(format_question_hierarchy(questions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
